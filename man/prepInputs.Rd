% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prepInputs.R
\name{prepInputs}
\alias{prepInputs}
\title{Download and optionally post process files}
\usage{
prepInputs(targetFile, url = NULL, archive = NULL, alsoExtract = NULL,
  destinationPath = ".", fun = NULL,
  quick = getOption("reproducible.quick"), overwrite = FALSE,
  purge = FALSE, useCache = getOption("reproducible.useCache", FALSE), ...)
}
\arguments{
\item{targetFile}{Character string giving the path to the eventual file
(raster, shapefile, csv, etc.) after downloading and extracting from a zip
or tar archive. This is the file \emph{before} it is passed to
\code{postProcess}. Currently, the internal checksumming does not checksum
the file after it is \code{postProcess}ed (e.g., cropped/reprojected/masked).
Using \code{Cache} around \code{prepInputs} will do a sufficient job in these cases.}

\item{url}{Optional character string indicating the URL to download from.
Normally, if used within a module, this url should be explicitly given as
sourceURL for an \code{expectsInput}. In that case, it will use the
module's checksums file to confirm that the download occurred correctly. If
URL is used here, an ad hoc checksums will be created in the
\code{destinationPath}. This will be used in subsequent calls to
\code{prepInputs}, comparing the file on hand with the ad hoc
\code{CHECKSUMS.txt}.}

\item{archive}{Optional character string giving the path of an archive
containing \code{targetFile}, or a vector giving a set of nested archives
(e.g., \code{c("xxx.tar", "inner.zip")}). If there is/are (an) inner
archive(s), but they are unknown, the function will try all until it finds
the \code{targetFile}}

\item{alsoExtract}{Optional character string naming files other than
\code{targetFile} that must be extracted from the \code{archive}.}

\item{destinationPath}{Character string of a directory in which to download
and save the file that comes from \code{url} and is also where the function
will look for \code{archive} or \code{targetFile}.}

\item{fun}{Character string indicating the function to use to load
\code{targetFile} into an \code{R} object.}

\item{quick}{Logical. This is passed internally to \code{\link{checksums}}
and \code{\link{downloadData}} (the quickCheck argument for both), and to
\code{\link{Cache}} (the quick argument). This results in faster, though
less robust checking of inputs. See the respective functions.}

\item{overwrite}{Logical. Should downloading and all the other actions occur
even if they pass the checksums or the files are all there.}

\item{purge}{When prepInputs is called from outside a module, it will write a
\code{CHECKSUMS.txt} file. If there is an incorrect \code{CHECKSUMS.txt},
this will purge it.}

\item{useCache}{Passed to Cache in various places. Default \code{FALSE}}

\item{...}{Additional arguments passed to \code{fun} (i.e,. user supplied),
 \code{\link{postProcess}} and \code{\link[reproducible]{Cache}}.
Since \code{...} is passed to \code{\link{postProcess}}, these will
\code{...} will also be passed into the inner
functions, e.g., \code{\link{cropInputs}}. See details and examples.}
}
\description{
This function can be used to prepare R objects from remote or local data
sources. The object of this function is to provide a reproducible version of
a series of commonly used steps for getting, loading, and processing data.
This function has two stages: Getting data (download, extracting from archives,
loading into R) and postProcessing (for \code{Spatial*} and \code{Raster*}
objects, this is crop, reproject, mask/intersect).
To trigger the first stage, provide \code{url} or \code{archive}.
To trigger the second stage, provide \code{studyArea} or \code{rasterToMatch}.
See examples.
}
\note{
This function is still experimental: use with caution.
}
\section{Stage 1 - Getting data}{


  \enumerate{
    \item Download from the web via either \code{\link[googledrive]{drive_download}},
    \code{\link[utils]{download.file}}, or \code{\link{downloadFromWebDB}};
    \item Extract from archive using \code{\link{unzip}} or \code{\link{untar}};
    \item Load into R using \code{\link[raster]{raster}},
    \code{\link[raster]{shapefile}}, or any other function passed in with \code{fun};
    \item Checksumming of all files during this process. This is put into a
    \file{CHECKSUMS.txt} file in the \code{destinationPath}, appending if it is
    already there, overwriting the entries for same files if entries already exist.
 }
}

\section{Stage 2 - Post processing}{


  This will be triggered if either \code{rasterToMatch} or \code{studyArea}
  is supplied.

  \enumerate{
    \item Fix errors. Currently only errors fixed are for \code{SpatialPolygons}
    using \code{buffer(..., width = 0)};
    \item Crop using \code{\link{cropInputs}};
    \item Project using \code{\link{projectInputs}};
    \item Mask using \code{\link{maskInputs}};
    \item Determine file name \code{\link{determineFilename}} via \code{postProcessedFilename};
    \item Optionally, write that file name to disk via \code{\link{writeOutputs}}.
   }

  NOTE: checksumming does not occur during the post-processing stage, as
  there are no file downloads. To achieve fast results, wrap
  \code{prepInputs} with \code{Cache}.

  NOTE: \code{sf} objects are still very experimental.

\subsection{postProcessing of \code{Raster*} and \code{Spatial*} objects:}{

  If \code{rasterToMatch} or \code{studyArea} are used, then this will
  trigger several subsequent functions, specifically the sequence,
  \emph{Crop, reproject, mask}, which appears to be a common sequence in
  spatial simulation. See \code{\link{postProcess.spatialObjects}}.

  \emph{Understanding various combinations of \code{rasterToMatch}
  and/or \code{studyArea}:}
  Please see \code{\link{postProcess.spatialObjects}}.
 }
}

\examples{
# This function works within a module; however, currently,
#   \\cde{sourceURL} is not yet working as desired. Use \\code{url}.
\dontrun{
# Put chunks like this in your .inputObjects
if (!suppliedElsewhere("test", sim))
  sim$test <- Cache(prepInputs, "raster.tif", "downloadedArchive.zip",
                    destinationPath = dataPath(sim), studyArea = sim$studyArea,
                    rasterToMatch = sim$otherRasterTemplate, overwrite = TRUE)

# download a zip file from internet, unzip all files, load as shapefile, Cache the call
# First time: don't know all files - prepInputs will guess, if download file is an archive,
#   then extract all files, then if there is a .shp, it will load with raster::shapefile
dPath <- file.path(tempdir(), "ecozones")
shpEcozone <- prepInputs(destinationPath = dPath,
                         url = "http://sis.agr.gc.ca/cansis/nsdb/ecostrat/zone/ecozone_shp.zip")

# Robust to partial file deletions:
unlink(dir(dPath, full.names = TRUE)[1:3])
shpEcozone <- prepInputs(destinationPath = dPath,
                     url = "http://sis.agr.gc.ca/cansis/nsdb/ecostrat/zone/ecozone_shp.zip")
unlink(dPath, recursive = TRUE)

# Once this is done, can be more precise in operational code:
#  specify targetFile, alsoExtract, and fun, wrap with Cache
ecozoneFilename <- file.path(dPath, "ecozones.shp")
ecozoneFiles <- c("ecozones.dbf", "ecozones.prj",
                  "ecozones.sbn", "ecozones.sbx", "ecozones.shp", "ecozones.shx")
shpEcozone <- prepInputs(targetFile = ecozoneFilename,
                    url = "http://sis.agr.gc.ca/cansis/nsdb/ecostrat/zone/ecozone_shp.zip",
                    alsoExtract = ecozoneFiles,
                    fun = "shapefile", destinationPath = dPath)
unlink(dPath, recursive = TRUE)

#' # Add a study area to Crop and Mask to
# Create a "study area"
library(sp)
library(raster)
coords <- structure(c(-122.98, -116.1, -99.2, -106, -122.98, 59.9, 65.73, 63.58, 54.79, 59.9), .Dim = c(5L, 2L))
Sr1 <- Polygon(coords)
Srs1 <- Polygons(list(Sr1), "s1")
StudyArea <- SpatialPolygons(list(Srs1), 1L)
crs(StudyArea) <- "+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

#  specify targetFile, alsoExtract, and fun, wrap with Cache
ecozoneFilename <- file.path(dPath, "ecozones.shp")
# Note, you don't need to "alsoExtract" the archive... if the archive is not there, but the
#   targetFile is there, it will not redownload the archive.
ecozoneFiles <- c("ecozones.dbf", "ecozones.prj",
                  "ecozones.sbn", "ecozones.sbx", "ecozones.shp", "ecozones.shx")
shpEcozoneSm <- Cache(prepInputs,
                         url = "http://sis.agr.gc.ca/cansis/nsdb/ecostrat/zone/ecozone_shp.zip",
                         targetFile = reproducible::asPath(ecozoneFilename),
                         alsoExtract = reproducible::asPath(ecozoneFiles),
                         studyArea = StudyArea,
                         fun = "shapefile", destinationPath = dPath,
                         postProcessedFilename = "EcozoneFile.shp") # passed to determineFilename

plot(shpEcozone)
plot(shpEcozoneSm, add = TRUE, col = "red")
unlink(dPath)

# Big Raster, with crop and mask to Study Area - no reprojecting (lossy) of raster,
#   but the StudyArea does get reprojected, need to use rasterToMatch
dPath <- file.path(tempdir(), "LCC")
lcc2005Filename <- file.path(dPath, "LCC2005_V1_4a.tif")
url <- file.path("ftp://ftp.ccrs.nrcan.gc.ca/ad/NLCCLandCover",
                 "LandcoverCanada2005_250m/LandCoverOfCanada2005_V1_4.zip")

# messages received below may help for filling in more arguments in the subsequent call
LCC2005 <- prepInputs(url = url,
                     destinationPath = asPath(dPath),
                     studyArea = StudyArea)

plot(LCC2005)

# if wrapped with Cache, will be fast second time, very fast 3rd time (via memoised copy)
LCC2005 <- Cache(prepInputs, url = url,
                     targetFile = lcc2005Filename,
                     archive = asPath("LandCoverOfCanada2005_V1_4.zip"),
                     destinationPath = asPath(dPath),
                     studyArea = StudyArea)
}

}
\seealso{
\code{\link{downloadFile}}, \code{\link{extractFromArchive}},
         \code{\link{downloadFile}}, \code{\link{postProcess}}.
}
\author{
Eliot McIntire

Jean Marchal
}
